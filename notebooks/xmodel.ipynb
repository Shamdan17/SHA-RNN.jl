{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Knet\n",
    "\n",
    "include(\"../src/data.jl\")\n",
    "include(\"../src/xmodel.jl\")\n",
    "include(\"../src/train.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ../jld2/enwik8.jld2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadir = \"../data/enwik8\"\n",
    "jld2dir = \"../jld2/enwik8.jld2\"\n",
    "BATCHSIZE = 16\n",
    "\n",
    "if !isfile(jld2dir)\n",
    "    println(\"Reading data from directory: $datadir\")\n",
    "    println(\"Setting batch size to $BATCHSIZE\")\n",
    "    vocab = Vocab(\"$datadir/train.txt\")\n",
    "    trainfile = TextReader(\"$datadir/train.txt\", vocab)\n",
    "    validfile = TextReader(\"$datadir/valid.txt\", vocab)\n",
    "    testfile = TextReader(\"$datadir/test.txt\", vocab)\n",
    "    dtrn = TextData(trainfile, batchsize=BATCHSIZE)\n",
    "    ddev = TextData(validfile, batchsize=BATCHSIZE)\n",
    "    dtst = TextData(testfile, batchsize=BATCHSIZE)\n",
    "    println(\"Saving data from $jld2dir\")\n",
    "    Knet.save(jld2dir, \"dtrn\", dtrn, \"dtst\", dtst, \"ddev\", ddev)\n",
    "else \n",
    "    println(\"Loading data from $jld2dir\")\n",
    "    (dtrn, dtst, ddev) = Knet.load(jld2dir, \"dtrn\", \"dtst\", \"ddev\")\n",
    "    vocab = dtrn.src.vocab\n",
    "    if dtrn.batchsize != BATCHSIZE\n",
    "        changebatchsize!(dtrn, BATCHSIZE)\n",
    "        changebatchsize!(ddev, BATCHSIZE)\n",
    "        changebatchsize!(dtst, BATCHSIZE)\n",
    "    end;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding size: 1024\n",
      "hidden size: 1024\n",
      "layers: 2\n",
      "Collecting training data...\n",
      "epochs: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Initializing and Training Language Model\n",
      "└ @ Main In[16]:1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "306-element Array{Tuple{Array{Int16,2},Array{Int16,2}},1}:\n",
       " ([4 10 … 3 8; 19 8 … 12 4; … ; 10 4 … 17 3; 22 3 … 31 12], [10 9 … 8 22; 8 14 … 4 19; … ; 4 3 … 3 53; 3 55 … 12 5])      \n",
       " ([22 3 … 15 4; 19 4 … 12 7; … ; 53 18 … 3 11; 5 30 … 11 3], [3 57 … 4 3; 4 9 … 7 21; … ; 18 18 … 11 4; 30 24 … 3 13])    \n",
       " ([3 26 … 17 17; 21 9 … 16 5; … ; 4 5 … 4 9; 13 7 … 27 3], [26 6 … 17 3; 9 36 … 5 3; … ; 5 3 … 9 5; 7 21 … 3 18])         \n",
       " ([3 26 … 4 9; 3 26 … 11 7; … ; 5 3 … 23 3; 18 18 … 41 41], [26 4 … 9 5; 26 6 … 7 14; … ; 3 26 … 3 6; 18 75 … 41 1])      \n",
       " ([5 16 … 19 6; 14 4 … 4 19; … ; 6 9 … 23 3; 1 1 … 5 4], [16 6 … 6 76; 4 28 … 19 12; … ; 9 14 … 3 22; 1 49 … 4 17])       \n",
       " ([76 8 … 5 23; 12 6 … 3 5; … ; 22 8 … 26 4; 17 17 … 3 3], [8 10 … 23 32; 6 9 … 5 13; … ; 8 10 … 4 29; 17 40 … 3 3])      \n",
       " ([32 39 … 10 8; 13 4 … 9 3; … ; 29 4 … 4 27; 3 3 … 17 28], [39 8 … 8 20; 4 7 … 3 7; … ; 4 10 … 27 3; 3 3 … 28 3])        \n",
       " ([20 4 … 10 6; 7 11 … 33 37; … ; 3 42 … 6 11; 3 11 … 16 10], [4 3 … 6 24; 11 3 … 37 67; … ; 42 13 … 11 4; 11 6 … 10 5])  \n",
       " ([24 7 … 15 15; 67 67 … 14 3; … ; 4 11 … 4 14; 5 3 … 5 23], [7 6 … 15 16; 67 17 … 3 6; … ; 11 27 … 14 3; 3 8 … 23 27])   \n",
       " ([16 10 … 83 4; 6 21 … 3 5; … ; 3 7 … 22 3; 27 3 … 10 4], [10 6 … 4 9; 21 6 … 5 7; … ; 7 9 … 3 18; 3 55 … 4 9])          \n",
       " ([9 7 … 4 3; 7 5 … 43 13; … ; 18 18 … 11 16; 9 5 … 21 3], [7 15 … 3 24; 5 12 … 13 7; … ; 18 55 … 16 15; 5 12 … 3 18])    \n",
       " ([24 4 … 9 11; 7 20 … 14 4; … ; 15 15 … 10 19; 18 18 … 22 8], [4 21 … 11 7; 20 11 … 4 24; … ; 15 4 … 19 23; 18 4 … 8 10])\n",
       " ([7 14 … 3 8; 24 23 … 17 17; … ; 23 27 … 3 6; 10 4 … 7 5], [14 4 … 8 22; 23 3 … 17 28; … ; 27 3 … 6 19; 4 11 … 5 23])    \n",
       " ⋮                                                                                                                        \n",
       " ([10 3 … 3 24; 4 3 … 10 4; … ; 4 7 … 5 7; 8 9 … 3 6], [3 13 … 24 6; 3 26 … 4 5; … ; 7 21 … 7 19; 9 3 … 6 9])             \n",
       " ([6 15 … 5 7; 5 17 … 10 35; … ; 19 4 … 9 27; 9 14 … 13 4], [15 35 … 7 8; 17 17 … 35 28; … ; 4 11 … 27 1; 14 3 … 4 3])    \n",
       " ([8 9 … 12 3; 28 3 … 10 7; … ; 1 1 … 12 14; 3 6 … 14 8], [9 3 … 3 1; 3 22 … 7 9; … ; 1 71 … 14 7; 6 10 … 8 51])          \n",
       " ([1 49 … 5 12; 9 15 … 79 7; … ; 7 4 … 10 17; 51 28 … 19 7], [49 3 … 12 4; 15 4 … 7 9; … ; 4 10 … 17 17; 28 3 … 7 9])     \n",
       " ([4 44 … 10 3; 9 21 … 4 12; … ; 17 27 … 5 23; 9 6 … 26 8], [44 62 … 3 8; 21 3 … 12 14; … ; 27 3 … 23 27; 6 10 … 8 29])   \n",
       " ([8 22 … 13 4; 14 3 … 17 17; … ; 27 3 … 16 4; 29 4 … 4 10], [22 3 … 4 3; 3 24 … 17 28; … ; 3 54 … 4 3; 4 9 … 10 4])      \n",
       " ([3 18 … 3 26; 28 3 … 9 15; … ; 3 8 … 4 10; 4 11 … 35 7], [18 18 … 26 6; 3 4 … 15 4; … ; 8 22 … 10 5; 11 5 … 7 11])      \n",
       " ([6 11 … 7 5; 4 3 … 4 9; … ; 5 6 … 5 7; 11 11 … 8 9], [11 3 … 5 7; 3 8 … 9 3; … ; 6 7 … 7 8; 11 3 … 9 6])                \n",
       " ([7 72 … 6 6; 3 6 … 3 26; … ; 8 9 … 4 3; 6 12 … 42 13], [72 4 … 6 27; 6 22 … 26 7; … ; 9 4 … 3 22; 12 3 … 13 4])         \n",
       " ([27 15 … 42 46; 7 5 … 11 4; … ; 22 6 … 19 23; 4 3 … 4 12], [15 8 … 46 37; 5 13 … 4 3; … ; 6 29 … 23 3; 3 26 … 12 6])    \n",
       " ([37 37 … 3 23; 3 62 … 5 5; … ; 3 14 … 4 3; 6 5 … 5 20], [37 59 … 23 4; 62 4 … 5 4; … ; 14 4 … 3 50; 5 7 … 20 40])       \n",
       " ([4 6 … 7 9; 4 14 … 3 10; … ; 50 11 … 4 3; 40 34 … 34 34], [6 10 … 9 3; 14 3 … 10 4; … ; 11 12 … 3 8; 34 34 … 34 26])    "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@info \"Initializing and Training Language Model\"\n",
    "epochs, em_size, hidden_size, layers = 15, 1024, 1024, 2\n",
    "println(\"embedding size: \", em_size)\n",
    "println(\"hidden size: \", hidden_size)\n",
    "println(\"layers: \", layers)\n",
    "\n",
    "println(\"Collecting training data...\")\n",
    "println(\"epochs: \", epochs)\n",
    "ctrn = collect(dtrn)\n",
    "trn = collect(flatten(shuffle!(ctrn) for i in 1:epochs))\n",
    "trnmini = ctrn[1:20]\n",
    "dev = collect(ddev);\n",
    "\n",
    "# model = XModel(em_size, hidden_size, vocab; layers=layers, dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Starting training, total iteration no: 82410\n",
      "└ @ Main In[17]:1\n",
      "\n",
      "┣                    ┫ [0.00%, 1/82410, 00:55/1258:38:06, 54.98s/i] (trn = (loss = (0.8420045f0,), ppl = (2.3210146f0,), bpc = (1.2147556847848042,)), dev = (loss = 0.9809018f0, ppl = 2.66686f0, bpc = 1.41514213035086))\n",
      "┣█▎                  ┫ [6.67%, 5494/82410, 46:38/11:39:25, 2.00i/s] (trn = (loss = (0.87678576f0,), ppl = (2.403163f0,), bpc = (1.264934460887768,)), dev = (loss = 0.9875315f0, ppl = 2.6845994f0, bpc = 1.4247067734959442))\n",
      "┣██▋                 ┫ [13.33%, 10988/82410, 01:33:25/11:40:38, 1.96i/s] (trn = (loss = (0.8767683f0,), ppl = (2.403121f0,), bpc = (1.2649092654294165,)), dev = (loss = 0.98394436f0, ppl = 2.6749866f0, bpc = 1.4195316435488314))\n",
      "┣████                ┫ [20.00%, 16482/82410, 02:19:01/11:35:03, 2.01i/s] (trn = (loss = (0.86140376f0,), ppl = (2.3664804f0,), bpc = (1.2427429375076617,)), dev = (loss = 0.97802615f0, ppl = 2.659202f0, bpc = 1.410993478855422))"
     ]
    }
   ],
   "source": [
    "@info \"Starting training, total iteration no: $(length(trn))\"\n",
    "model.rnn.c, model.rnn.h = 0, 0\n",
    "# initopt!(model, length(trn); lr=0.001)\n",
    "\n",
    "model = train!(model, length(ctrn), trn, dev, trnmini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Starting training, total iteration no: 27470\n",
      "└ @ Main In[5]:1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:13:25  ->  Dev set scores : (loss = 0.95302016f0, ppl = 2.5935307f0, bpc = 1.3749174521058594)\n",
      "15:54:53  ->  5494 iteration: Training set scores : (loss = 0.9501285f0, ppl = 2.586042f0, bpc = 1.3707456689438804)\n",
      "15:55:38  ->  Dev set scores after 5494 iteration : (loss = 0.99072576f0, ppl = 2.6931884f0, bpc = 1.4293151346171387)\n",
      "16:38:44  ->  10988 iteration: Training set scores : (loss = 0.94604945f0, ppl = 2.5755148f0, bpc = 1.3648608525879822)\n",
      "16:39:33  ->  Dev set scores after 10988 iteration : (loss = 0.9717933f0, ppl = 2.6426792f0, bpc = 1.40200136595506)\n",
      "17:22:34  ->  16482 iteration: Training set scores : (loss = 0.9210054f0, ppl = 2.5118146f0, bpc = 1.3287299633727945)\n",
      "17:23:22  ->  Dev set scores after 16482 iteration : (loss = 0.9586783f0, ppl = 2.6082468f0, bpc = 1.3830804366464118)\n",
      "18:00:32  ->  21976 iteration: Training set scores : (loss = 0.89718586f0, ppl = 2.452691f0, bpc = 1.294365593955944)\n",
      "18:01:22  ->  Dev set scores after 21976 iteration : (loss = 0.9467925f0, ppl = 2.5774293f0, bpc = 1.36593282045081)\n",
      "18:01:22  ->  new best dev score, saving checkpoint..\n",
      "18:39:26  ->  27470 iteration: Training set scores : (loss = 0.87593603f0, ppl = 2.4011219f0, bpc = 1.2637085685524179)\n",
      "18:40:15  ->  Dev set scores after 27470 iteration : (loss = 0.93983626f0, ppl = 2.5595622f0, bpc = 1.3558971168250125)\n",
      "18:40:15  ->  new best dev score, saving checkpoint..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XModel(Embed(P(KnetArray{Float32,2}(1024,206))), LSTM(input=1024,hidden=1024,layers=2,dropout=0.2), Boom(Linear(P(KnetArray{Float32,2}(4096,1024)), P(KnetArray{Float32,1}(4096))), Linear(P(KnetArray{Float32,2}(1024,4096)), P(KnetArray{Float32,1}(1024))), 0.1, false, gelu), Linear(P(KnetArray{Float32,2}(206,1024)), P(KnetArray{Float32,1}(206))), 0.2, Vocab(Dict(\"54\" => 67,\"101\" => 4,\"41\" => 52,\"65\" => 38,\"168\" => 126,\"159\" => 175,\"228\" => 183,\"190\" => 117,\"227\" => 96,\"88\" => 104…), [\"<s>\", \"<unk>\", \"32\", \"101\", \"116\", \"97\", \"105\", \"111\", \"110\", \"114\"  …  \"210\", \"239\", \"211\", \"198\", \"212\", \"240\", \"205\", \"220\", \"222\", \"200\"], 2, 1, split))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@info \"Starting training, total iteration no: $(length(trn))\"\n",
    "model.rnn.c, model.rnn.h = 0, 0\n",
    "# initopt!(model, length(trn); lr=0.001)\n",
    "\n",
    "model = train!(model, length(ctrn), trn, dev, trnmini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Finished training, Starting evaluation ...\n",
      "└ @ Main In[6]:1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set scores:       (loss = 0.800062f0, ppl = 2.225679f0, bpc = 1.1542454808878846)\n",
      "Development set scores:    (loss = 0.9398322f0, ppl = 2.559552f0, bpc = 1.3558912694148832)\n",
      "Test set scores:           (loss = 0.9556811f0, ppl = 2.600441f0, bpc = 1.3787563628470936)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Saving the model as model_x.jld2\n",
      "└ @ Main In[6]:12\n"
     ]
    }
   ],
   "source": [
    "@info \"Finished training, Starting evaluation ...\"\n",
    "trnloss = loss(model, dtrn);\n",
    "println(\"Training set scores:       \", report_lm(trnloss))\n",
    "devloss = loss(model, ddev);\n",
    "println(\"Development set scores:    \", report_lm(devloss))\n",
    "testloss = loss(model, dtst);\n",
    "println(\"Test set scores:           \", report_lm(testloss))\n",
    "\n",
    "# @info \"Generate text using the trained model\"\n",
    "# print(generate(model, start=\"United Nations \", maxlength=1024))\n",
    "\n",
    "@info \"Saving the model as model_x.jld2\"\n",
    "Knet.save(\"model_x_new.jld2\", \"model\", model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XModel(Embed(P(KnetArray{Float32,2}(1024,206))), LSTM(input=1024,hidden=1024,layers=2,dropout=0.2), Boom(Linear(P(KnetArray{Float32,2}(4096,1024)), P(KnetArray{Float32,1}(4096))), Linear(P(KnetArray{Float32,2}(1024,4096)), P(KnetArray{Float32,1}(1024))), 0.1, false, gelu), Linear(P(KnetArray{Float32,2}(206,1024)), P(KnetArray{Float32,1}(206))), 0.2, Vocab(Dict(\"54\" => 67,\"101\" => 4,\"41\" => 52,\"65\" => 38,\"168\" => 126,\"159\" => 175,\"228\" => 183,\"190\" => 117,\"227\" => 96,\"88\" => 104…), [\"<s>\", \"<unk>\", \"32\", \"101\", \"116\", \"97\", \"105\", \"111\", \"110\", \"114\"  …  \"210\", \"239\", \"211\", \"198\", \"212\", \"240\", \"205\", \"220\", \"222\", \"200\"], 2, 1, split))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Knet.load(\"model_x_new.jld2\", \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for par in params(model)\n",
    "    par.opt = nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
